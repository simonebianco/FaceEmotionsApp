{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4511,"status":"ok","timestamp":1682787163900,"user":{"displayName":"Simone Bianco","userId":"04319024048141808064"},"user_tz":-120},"id":"kyOm5WOLizxj","outputId":"76d7a967-61aa-46c3-a87b-00cf8c1807d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["2.12.0\n"]}],"source":["import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","import itertools\n","import pandas as pd\n","import os\n","from keras.utils import load_img\n","print(tf.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QbsNt_nFv70f"},"outputs":[],"source":["# Unzip data\n","!unzip /content/FER-2013.zip"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":306,"status":"ok","timestamp":1682787427995,"user":{"displayName":"Simone Bianco","userId":"04319024048141808064"},"user_tz":-120},"id":"p9Ag0ku7i3JD"},"outputs":[],"source":["train_path = '/content/train'\n","test_path  = '/content/test'"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":244,"status":"ok","timestamp":1682787234143,"user":{"displayName":"Simone Bianco","userId":"04319024048141808064"},"user_tz":-120},"id":"fftQha8qjJQI"},"outputs":[],"source":["# FUNCTIONS\n","def plot_images(train_path):\n","  emotions = os.listdir(train_path)\n","  fig, axs = plt.subplots(7, 7, figsize=(18, 10))\n","  for i, emotion in enumerate(emotions):\n","      axs[i, 0].text(0.5, 0.5, emotion, ha='center', va='center', fontsize=14)\n","      axs[i, 0].axis('off')\n","      emotion_path = os.path.join(train_path, emotion)\n","      list_files = os.listdir(emotion_path)\n","      for j in range(6):\n","          idx = i*6+j\n","          if(idx < len(axs.flat)):\n","              image = load_img(os.path.join(emotion_path, list_files[j]))\n","              axs[i, j+1].imshow(image)\n","              axs[i, j+1].axis(\"off\")\n","  plt.suptitle(\"Emotion Class\")\n","  plt.show()\n","\n","def load_data(train_path, test_path, IMG_SIZE, BATCH_SIZE):\n","\t\t\t\ttrain_set = tf.keras.utils.image_dataset_from_directory(\n","\t\t\t\t\t\t\t\t\t\ttrain_path,\n","\t\t\t\t\t\t\t\t\t\tseed=42,\n","\t\t\t\t\t\t\t\t\t\tvalidation_split=0.2,\n","\t\t\t\t\t\t\t\t\t\tsubset='training',\n","\t\t\t\t\t\t\t\t\t\timage_size=(IMG_SIZE, IMG_SIZE),\n","\t\t\t\t\t\t\t\t\t\tbatch_size=BATCH_SIZE,\n","\t\t\t\t\t\t\t\t\t\tlabels='inferred',\n","\t\t\t\t\t\t\t\t\t\tshuffle=True,\n","                    color_mode = \"grayscale\"\n","\t\t\t\t\t\t\t\t\t\t)\n","\n","\t\t\t\tvalid_set = tf.keras.utils.image_dataset_from_directory(\n","\t\t\t\t\t\t\t\t\t\ttrain_path,\n","\t\t\t\t\t\t\t\t\t\tseed=42,\n","\t\t\t\t\t\t\t\t\t\tvalidation_split=0.2,\n","\t\t\t\t\t\t\t\t\t\tsubset='validation',\n","\t\t\t\t\t\t\t\t\t\timage_size=(IMG_SIZE, IMG_SIZE),\n","\t\t\t\t\t\t\t\t\t\tbatch_size=BATCH_SIZE,\n","\t\t\t\t\t\t\t\t\t\tlabels='inferred',\n","\t\t\t\t\t\t\t\t\t\tshuffle=True,\n","\t\t\t\t\t\t\t\t\t\tcolor_mode = \"grayscale\"\n","\t\t\t\t\t\t\t\t\t\t)\n","\n","\t\t\t\ttest_set = tf.keras.utils.image_dataset_from_directory(\n","\t\t\t\t\t\t\t\t\t\ttest_path,\n","\t\t\t\t\t\t\t\t\t\tseed=42,\n","\t\t\t\t\t\t\t\t\t\timage_size=(IMG_SIZE, IMG_SIZE),\n","\t\t\t\t\t\t\t\t\t\tbatch_size=BATCH_SIZE,\n","\t\t\t\t\t\t\t\t\t\tlabels='inferred',\n","\t\t\t\t\t\t\t\t\t\tshuffle=False,\n","\t\t\t\t\t\t\t\t\t\tcolor_mode = \"grayscale\"\n","\t\t\t\t\t\t\t\t\t\t)\n","\t\n","\t\t\t\treturn train_set, valid_set, test_set\n","\n","def normalize(img, label):\n","    img = tf.cast(img, tf.float32)\n","    label = tf.cast(label, tf.float32)\n","    return tf.divide(img, 255.), label\n","\n","def augmentation(image, label):   \n","    image = tf.image.random_flip_left_right(image)  \n","    image = tf.image.rot90(image)  \n","    return image, label\n","\n","def plot_lrs(train_history, epochs):  \n","    lrs = 1e-6 * (10 ** (np.arange(epochs) / 20))  \n","    plt.figure(figsize=(18, 10))   \n","    plt.semilogx(lrs, train_history.history[\"val_loss\"], color='#f97306', linestyle='dashed', label='Learning Rate')\n","    plt.legend(loc='best')     \n","    plt.xlabel(\"Learning Rate\")  \n","    plt.ylabel(\"Loss\")  \n","    plt.title(\"Learning rate vs. loss\")  \n","    plt.show()  \n","    plt.savefig('lrs.png')\n","\n","\n","def plot_loss_acc(train_history):  \n","    epochs = range(len(train_history.history['accuracy']))  \n","    plt.figure(figsize=(18, 10))  \n","    plt.subplot(1, 2, 1)  \n","    plt.plot(epochs, train_history.history['accuracy'], color='#f97306', linestyle='dashed', label='Training accuracy')  \n","    plt.plot(epochs, train_history.history['val_accuracy'], color='#808080', linestyle='dashed',  \n","    label='Validation accuracy')  \n","    plt.legend(loc='best')  \n","    plt.grid(linewidth=1)  \n","    plt.title('Training and validation accuracy')  \n","    plt.subplot(1, 2, 2)  \n","    plt.plot(epochs, train_history.history['loss'], color='#f97306', linestyle='dashed', label='Training Loss')  \n","    plt.plot(epochs, train_history.history['val_loss'], color='#808080', linestyle='dashed', label='Validation Loss')  \n","    plt.legend(loc='best')  \n","    plt.grid(linewidth=1)  \n","    plt.title('Training and validation loss')  \n","    plt.legend()  \n","    plt.show()   \n","    plt.savefig('loss_accuracy.png')\n","\n","def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(18, 10), text_size=7):\n","    cm = confusion_matrix(y_true, y_pred)\n","    cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] \n","    n_classes = cm.shape[0] \n","    fig, ax = plt.subplots(figsize=figsize)\n","    cax = ax.matshow(cm, cmap='Oranges')\n","    fig.colorbar(cax)   \n","    if classes:\n","      labels = classes\n","    else:\n","      labels = np.arange(cm.shape[0])   \n","    ax.set(title=\"Confusion Matrix\",\n","    xlabel=\"Predicted label\",\n","    ylabel=\"True label\",\n","    xticks=np.arange(n_classes),\n","    yticks=np.arange(n_classes),\n","    xticklabels=labels, \n","    yticklabels=labels)\n","    ax.xaxis.set_label_position(\"bottom\")\n","    ax.xaxis.tick_bottom()\n","    threshold = (cm.max() + cm.min()) / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n","        horizontalalignment=\"center\",\n","        color=\"white\" if cm[i, j] > threshold else \"black\",\n","        size=text_size)         "]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":643,"status":"ok","timestamp":1682787344612,"user":{"displayName":"Simone Bianco","userId":"04319024048141808064"},"user_tz":-120},"id":"boiFtwp3jMid"},"outputs":[],"source":["# CALLBACKS\n","class AccuracyCallback(tf.keras.callbacks.Callback):  \n","    def on_epoch_end(self, epoch, logs={}):  \n","        if logs.get('accuracy') >= 0.95:  \n","            print(\"\\nReached 95% accuracy so cancelling training\")  \n","            self.model.stop_training = True  \n","  \n","accuracy_call = AccuracyCallback()  \n","early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1) \n","checkpoint = tf.keras.callbacks.ModelCheckpoint('model.h5', save_best_only=True)  \n","lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-6 * 10 ** (epoch / 20))\n","\n","reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n","                              factor=0.2,\n","                              patience=3,\n","                              verbose=1,\n","                              min_delta=0.0001)\n","\n","callbacks_list = [accuracy_call, reduce_lr]"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6729,"status":"ok","timestamp":1682787438912,"user":{"displayName":"Simone Bianco","userId":"04319024048141808064"},"user_tz":-120},"id":"BG0TXYUAjPGN","outputId":"5d03d9f5-80ce-474d-e58a-ca84774b02d4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 28709 files belonging to 7 classes.\n","Using 22968 files for training.\n","Found 28709 files belonging to 7 classes.\n","Using 5741 files for validation.\n","Found 7178 files belonging to 7 classes.\n"]}],"source":["## PARAMETERS\n","IMG_SIZE = 48\n","BATCH_SIZE = 64\n","AUTOTUNE = tf.data.AUTOTUNE\n","\n","## LOAD DATA\n","train_set, valid_set, test_set = load_data(train_path, test_path, IMG_SIZE, BATCH_SIZE)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":346,"status":"ok","timestamp":1682787496085,"user":{"displayName":"Simone Bianco","userId":"04319024048141808064"},"user_tz":-120},"id":"oOQVOJlrjZ0x"},"outputs":[],"source":["# NORMALIZE  DATA\n","train_set = train_set.map(normalize, num_parallel_calls=AUTOTUNE)\n","valid_set = valid_set.map(normalize, num_parallel_calls=AUTOTUNE)\n","test_set = test_set.map(normalize, num_parallel_calls=AUTOTUNE)\n","\n","# AUGMENT DATA\n","#train_set = train_set.map(augmentation, num_parallel_calls=AUTOTUNE)\n","#valid_set = valid_set.map(augmentation, num_parallel_calls=AUTOTUNE)\n","\n","# CACHE DATE\n","train_set = train_set.cache().prefetch(AUTOTUNE) \n","valid_set = valid_set.cache().prefetch(AUTOTUNE) "]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":715,"status":"ok","timestamp":1682787498927,"user":{"displayName":"Simone Bianco","userId":"04319024048141808064"},"user_tz":-120},"id":"Pjfg4zzQSW5T","outputId":"dfcf19ae-6f2d-4864-b6cd-e29062ce1308"},"outputs":[{"name":"stdout","output_type":"stream","text":["(64, 48, 48, 1)\n","(64,)\n"]}],"source":["for i , x in train_set.take(1):\n","  print(i.shape)\n","  print(x.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iqhsLSI7hVPF"},"outputs":[],"source":["def create_model():\n","    model = tf.keras.Sequential()\n","    # Input\n","    model.add(tf.keras.Input(shape=([48, 48, 1]))),\n","    # 1 Conv\n","    model.add(tf.keras.layers.Conv2D(128,(3,3),padding = \"same\", activation = \"relu\")),\n","    model.add(tf.keras.layers.BatchNormalization()),\n","    model.add(tf.keras.layers.MaxPool2D(2,2)),\n","    model.add(tf.keras.layers.Dropout(0.25))\n","    # 2 Conv\n","    model.add(tf.keras.layers.Conv2D(256,(3,3),padding = \"same\", activation = \"relu\")),\n","    model.add(tf.keras.layers.BatchNormalization()),\n","    model.add(tf.keras.layers.MaxPool2D(2,2)),\n","    model.add(tf.keras.layers.Dropout(0.25))\n","    # 3 Conv\n","    model.add(tf.keras.layers.Conv2D(512,(3,3),padding = \"same\", activation = \"relu\")),\n","    model.add(tf.keras.layers.BatchNormalization()),\n","    model.add(tf.keras.layers.MaxPool2D(2,2)),\n","    model.add(tf.keras.layers.Dropout(0.25))\n","    # 4 Conv\n","    model.add(tf.keras.layers.Conv2D(512,(3,3),padding = \"same\", activation = \"relu\")),\n","    model.add(tf.keras.layers.BatchNormalization()),\n","    model.add(tf.keras.layers.MaxPool2D(2,2)),\n","    model.add(tf.keras.layers.Dropout(0.25))\n","    # Flattend\n","    model.add(tf.keras.layers.Flatten())\n","    # 1 Dense\n","    model.add(tf.keras.layers.Dense(256, activation='relu'))\n","    model.add(tf.keras.layers.BatchNormalization())\n","    model.add(tf.keras.layers.Dropout(0.25))\n","    # 2 Dense\n","    model.add(tf.keras.layers.Dense(512, activation='relu'))\n","    model.add(tf.keras.layers.BatchNormalization())\n","    model.add(tf.keras.layers.Dropout(0.25))\n","    # Output\n","    model.add(tf.keras.layers.Dense(7, activation='softmax'))\n","\n","    return model\n","\n","model = create_model()\n","\n","opt = tf.keras.optimizers.Adam(learning_rate = 0.001)\n","\n","model.compile(optimizer = opt,\n","              loss = \"sparse_categorical_crossentropy\",\n","              metrics = [\"accuracy\"]) \n","\n","# FIT THE MODEL\n","tf.keras.backend.clear_session()  \n","EPOCHS = 50\n","history = model.fit(train_set, \n","                    validation_data=valid_set, \n","                    epochs=EPOCHS, \n","                    verbose=1,\n","                    callbacks=callbacks_list\n","                    )  "]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":367,"status":"ok","timestamp":1682788505377,"user":{"displayName":"Simone Bianco","userId":"04319024048141808064"},"user_tz":-120},"id":"9pJuKK-D_DkO"},"outputs":[],"source":["# SAVE HISTORY \n","hist_df = pd.DataFrame(history.history) \n","hist_csv_file = 'history.csv'\n","with open(hist_csv_file, mode='w') as f:\n","    hist_df.to_csv(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CFUDInBZ9lOj"},"outputs":[],"source":["# PLOT MODEL\n","from tensorflow.keras.utils import plot_model\n","plot_model(model, show_shapes=True, to_file='model_architecture.png')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6fD3k844-OrW"},"outputs":[],"source":["plot_images(train_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eASReCfBAHaq"},"outputs":[],"source":["plot_lrs(history, EPOCHS)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":720},"executionInfo":{"elapsed":730,"status":"ok","timestamp":1682789046035,"user":{"displayName":"Simone Bianco","userId":"04319024048141808064"},"user_tz":-120},"id":"X_MjLGPAN4Jn","outputId":"2c2a07e6-2f1b-49cf-d5aa-6a7111b4108a"},"outputs":[],"source":["plot_loss_acc(history)"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":304,"status":"ok","timestamp":1682788572698,"user":{"displayName":"Simone Bianco","userId":"04319024048141808064"},"user_tz":-120},"id":"BZay1xjZL0J2"},"outputs":[],"source":["# Save model to JSON\n","model_json = model.to_json()\n","with open(\"model.json\", \"w\") as json_file:\n","    json_file.write(model_json)"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1682788574354,"user":{"displayName":"Simone Bianco","userId":"04319024048141808064"},"user_tz":-120},"id":"giWnpBaMJHg1"},"outputs":[],"source":["# Save the weights \n","model.save_weights(\"weight.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O86cKJckNrpw"},"outputs":[],"source":["# PRED LABELS\n","test_prediction = model.predict(test_set)\n","test_prediction_2 = test_prediction.argmax(axis=1)\n","\n","# TRUE LABELS\n","test_label = []\n","for features, label in test_set:\n","    test_label.append(label.numpy())\n","\n","test_label_2 = []\n","for i in test_label:\n","    for j in i:\n","        test_label_2.append(j)          "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JAQPj8r89vDK"},"outputs":[],"source":["# CONFUSION MATRIX\n","classes = ['Angry', 'Disgust', 'Fear', 'Happy','Sad', 'Surprise', 'Neutral']\n","make_confusion_matrix(test_label_2, test_prediction_2, classes=classes) "]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":433,"status":"ok","timestamp":1682788877158,"user":{"displayName":"Simone Bianco","userId":"04319024048141808064"},"user_tz":-120},"id":"guwHbmc8WEKL"},"outputs":[],"source":["# CLASSIFICATION REPORT\n","from sklearn.metrics import classification_report\n","cr = classification_report(test_label_2, test_prediction_2, target_names=classes, output_dict=True)\n","df = pd.DataFrame(cr).transpose()\n","df = df.apply(lambda x: x.round(2))\n","df.to_csv('classification_report.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sLV-Ry1GCglS"},"outputs":[],"source":["# Download model and weights\n","from google.colab import files\n","files.download(\"history.csv\")\n","files.download(\"weight.h5\")\n","files.download(\"model.json\")\n","files.download(\"loss_accuracy.png\")\n","files.download(\"lrs.png\")\n","files.download(\"model_architecture.png\")\n","files.download(\"classification_report.csv\")"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOG2e+uH3O7Wwj2pKMzruzY","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
